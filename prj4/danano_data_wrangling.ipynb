{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "danano_data_wrangling.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ilguZU0QkECB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling Template"
      ]
    },
    {
      "metadata": {
        "id": "GCYq5Nb5kECE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gather"
      ]
    },
    {
      "metadata": {
        "id": "zQ_EZaLikECG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# Extract all the contents from a zipfile\n",
        "with zipfile.Zipfile('filename.zip', 'r') as myzip:\n",
        "  myzip.extractall()\n",
        "\n",
        "df = pd.read_csv('online-job-postings.csv')\n",
        "\n",
        "df.info\n",
        "df.head()\n",
        "\n",
        "df_clean = df.copy()\n",
        "\n",
        "df_clean = df_clean.rename(columns = {'old_col_name1':'new_col_name1',\n",
        "                                   'old_col_name2':'new_col_name2',\n",
        "                                   'old_col_name3':'new_col_name3'})\n",
        "\n",
        "replace_list = ['old_value1', 'old_value2', 'old_value3']\n",
        "\n",
        "for phrase in replace_list:\n",
        "  df_clean.StartDate.replace(phrase, 'new_value', inplace=True)\n",
        "  \n",
        "# Assertions in Python\n",
        "for phrase in replace_list:\n",
        "  assert phrase not in df_clean.StartDate.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zzw3UQYrm6aM",
        "colab_type": "code",
        "outputId": "7e7ce29e-5fea-43a8-a0d9-1258d897d046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "# Web Scraping\n",
        "import requests\n",
        "import os\n",
        "\n",
        "folder_name = 'ebert_reviews'\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "    \n",
        "url = 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save the HTML to a file\n",
        "for url in ebert_review_urls:\n",
        "    response = requests.get(url)\n",
        "    with open(os.path.join(folder_name, url.split('/')[-1]), mode = 'wb') as file:\n",
        "        file.write(response.content)\n",
        "              \n",
        "os.listdir(folder_name)\n",
        "\n",
        "import filecmp\n",
        "\n",
        "dc = filecmp.dircmp('ebert_reviews', 'ebert_reviews_solution')\n",
        "assert len(dc.common) == 88\n",
        "\n",
        "# Working with the HTML content in memory\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "with open (url) as file:\n",
        "    # soup = BeautifulSouop(url, 'lxml')\n",
        "    soup = BeautifulSoup(file, 'lxml')\n",
        "\n",
        "soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a17a07dc4683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# soup = BeautifulSouop(url, 'lxml')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8DBARln9J7cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "folder = 'rt_html'\n",
        "for movie_html in os.listdir(folder):\n",
        "    with open(os.path.join(folder, movie_html)) as file:\n",
        "        # Your code here\n",
        "        # Note: a correct implementation may take ~15 seconds to run\n",
        "        soup = BeautifulSoup(file, 'lxml')\n",
        "        title = soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
        "        audience_score = soup.find('div', class_='audience-score meter').find('span').contents[0][:-1]\n",
        "        num_audience_ratings = soup.find('div', class_ = 'audience-info hidden-xs superPageFontColor')\n",
        "        num_audience_ratings = num_audience_ratings.find_all('div')[1].contents[2].strip().replace(',','')\n",
        "        \n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                        'audience_score': int(audience_score),\n",
        "                        'number_of_audience_ratings': int(num_audience_ratings)})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'audience_score', 'number_of_audience_ratings'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gJVtuN-2J-KG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_pickle('df_solution.pkl')\n",
        "df.sort_values('title', inplace = True)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "df_solution.sort_values('title', inplace = True)\n",
        "df_solution.reset_index(inplace = True, drop = True)\n",
        "pd.testing.assert_frame_equal(df, df_solution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m0f5E7MzKAfN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "for ebert_review in glob.glob('ebert_reviews/*.txt'):\n",
        "    with open(ebert_review, encoding='utf-8') as file:\n",
        "        title = file.readline()[:-1]\n",
        "        # Your code here\n",
        "        review_url = file.readline()[:-1]\n",
        "        review_text = file.read()\n",
        "\n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                       'review_url': review_url,\n",
        "                       'review_text': review_text})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'review_url', 'review_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MyXahO0AKCOs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_pickle('df_solution.pkl')\n",
        "df.sort_values('title', inplace = True)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "df_solution.sort_values('title', inplace = True)\n",
        "df_solution.reset_index(inplace = True, drop = True)\n",
        "pd.testing.assert_frame_equal(df, df_solution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vKC0ZaoKG4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import wptools\n",
        "\n",
        "page = wptools.page('E.T._the_Extra-Terrestrial').get()\n",
        "page.data['image'][0]\n",
        "page.data['infobox']['director']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c4Ce-7oKKMLh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import wptools\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZ435ZxbKNax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "title_list = [\n",
        " 'The_Wizard_of_Oz_(1939_film)',\n",
        " 'Citizen_Kane',\n",
        " 'The_Third_Man',\n",
        " 'Get_Out_(film)',\n",
        " 'Mad_Max:_Fury_Road',\n",
        " 'The_Cabinet_of_Dr._Caligari',\n",
        " 'All_About_Eve',\n",
        " 'Inside_Out_(2015_film)',\n",
        " 'The_Godfather',\n",
        " 'Metropolis_(1927_film)',\n",
        " 'E.T._the_Extra-Terrestrial',\n",
        " 'Modern_Times_(film)',\n",
        " 'It_Happened_One_Night',\n",
        " \"Singin'_in_the_Rain\",\n",
        " 'Boyhood_(film)',\n",
        " 'Casablanca_(film)',\n",
        " 'Moonlight_(2016_film)',\n",
        " 'Psycho_(1960_film)',\n",
        " 'Laura_(1944_film)',\n",
        " 'Nosferatu',\n",
        " 'Snow_White_and_the_Seven_Dwarfs_(1937_film)',\n",
        " \"A_Hard_Day%27s_Night_(film)\",\n",
        " 'La_Grande_Illusion',\n",
        " 'North_by_Northwest',\n",
        " 'The_Battle_of_Algiers',\n",
        " 'Dunkirk_(2017_film)',\n",
        " 'The_Maltese_Falcon_(1941_film)',\n",
        " 'Repulsion_(film)',\n",
        " '12_Years_a_Slave_(film)',\n",
        " 'Gravity_(2013_film)',\n",
        " 'Sunset_Boulevard_(film)',\n",
        " 'King_Kong_(1933_film)',\n",
        " 'Spotlight_(film)',\n",
        " 'The_Adventures_of_Robin_Hood',\n",
        " 'Rashomon',\n",
        " 'Rear_Window',\n",
        " 'Selma_(film)',\n",
        " 'Taxi_Driver',\n",
        " 'Toy_Story_3',\n",
        " 'Argo_(2012_film)',\n",
        " 'Toy_Story_2',\n",
        " 'The_Big_Sick',\n",
        " 'Bride_of_Frankenstein',\n",
        " 'Zootopia',\n",
        " 'M_(1931_film)',\n",
        " 'Wonder_Woman_(2017_film)',\n",
        " 'The_Philadelphia_Story_(film)',\n",
        " 'Alien_(film)',\n",
        " 'Bicycle_Thieves',\n",
        " 'Seven_Samurai',\n",
        " 'The_Treasure_of_the_Sierra_Madre_(film)',\n",
        " 'Up_(2009_film)',\n",
        " '12_Angry_Men_(1957_film)',\n",
        " 'The_400_Blows',\n",
        " 'Logan_(film)',\n",
        " 'All_Quiet_on_the_Western_Front_(1930_film)',\n",
        " 'Army_of_Shadows',\n",
        " 'Arrival_(film)',\n",
        " 'Baby_Driver',\n",
        " 'A_Streetcar_Named_Desire_(1951_film)',\n",
        " 'The_Night_of_the_Hunter_(film)',\n",
        " 'Star_Wars:_The_Force_Awakens',\n",
        " 'Manchester_by_the_Sea_(film)',\n",
        " 'Dr._Strangelove',\n",
        " 'Frankenstein_(1931_film)',\n",
        " 'Vertigo_(film)',\n",
        " 'The_Dark_Knight_(film)',\n",
        " 'Touch_of_Evil',\n",
        " 'The_Babadook',\n",
        " 'The_Conformist_(film)',\n",
        " 'Rebecca_(1940_film)',\n",
        " \"Rosemary%27s_Baby_(film)\",\n",
        " 'Finding_Nemo',\n",
        " 'Brooklyn_(film)',\n",
        " 'The_Wrestler_(2008_film)',\n",
        " 'The_39_Steps_(1935_film)',\n",
        " 'L.A._Confidential_(film)',\n",
        " 'Gone_with_the_Wind_(film)',\n",
        " 'The_Good,_the_Bad_and_the_Ugly',\n",
        " 'Skyfall',\n",
        " 'Rome,_Open_City',\n",
        " 'Tokyo_Story',\n",
        " 'Hell_or_High_Water_(film)',\n",
        " 'Pinocchio_(1940_film)',\n",
        " 'The_Jungle_Book_(2016_film)',\n",
        " 'La_La_Land_(film)',\n",
        " 'Star_Trek_(film)',\n",
        " 'High_Noon',\n",
        " 'Apocalypse_Now',\n",
        " 'On_the_Waterfront',\n",
        " 'The_Wages_of_Fear',\n",
        " 'The_Last_Picture_Show',\n",
        " 'Harry_Potter_and_the_Deathly_Hallows_–_Part_2',\n",
        " 'The_Grapes_of_Wrath_(film)',\n",
        " 'Roman_Holiday',\n",
        " 'Man_on_Wire',\n",
        " 'Jaws_(film)',\n",
        " 'Toy_Story',\n",
        " 'The_Godfather_Part_II',\n",
        " 'Battleship_Potemkin'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlvpriZpKP5M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "folder_name = 'bestofrt_posters'\n",
        "# Make directory if it doesn't already exist\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTYoJaxUWg_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "page = wptools.page('Skyfall', silent=True).get()\n",
        "page.data['image'][0]['url']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fEtFmGMkWi6u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# List of dictionaries to build and convert to a DataFrame later\n",
        "df_list = []\n",
        "image_errors = {}\n",
        "# images = {}\n",
        "for title in title_list:\n",
        "    try:\n",
        "        # This cell is slow so print ranking to gauge time remaining\n",
        "        ranking = title_list.index(title) + 1\n",
        "        print(ranking)\n",
        "        page = wptools.page(title, silent=True).get()\n",
        "        # Your code here (three lines)\n",
        "        images = page.data['image']\n",
        "        # First image is usually the poster\n",
        "        first_image_url = images[0]['url']\n",
        "        r = requests.get(first_image_url)\n",
        "        # Download movie poster image\n",
        "        i = Image.open(BytesIO(r.content))\n",
        "        image_file_format = first_image_url.split('.')[-1]\n",
        "        i.save(folder_name + \"/\" + str(ranking) + \"_\" + title + '.' + image_file_format)\n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'ranking': int(ranking),\n",
        "                        'title': title,\n",
        "                        'poster_url': first_image_url})\n",
        "    \n",
        "    # Not best practice to catch all exceptions but fine for this short script\n",
        "    except Exception as e:\n",
        "        print(str(ranking) + \"_\" + title + \": \" + str(e))\n",
        "        image_errors[str(ranking) + \"_\" + title] = images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brpXgm2kWnio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "afor key in image_errors.keys():\n",
        "    print(key)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUKAAEPmWqEM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Inspect unidentifiable images and download them individually\n",
        "for rank_title, images in image_errors.items():\n",
        "    if rank_title == '22_A_Hard_Day%27s_Night_(film)':\n",
        "        url = 'https://upload.wikimedia.org/wikipedia/en/4/47/A_Hard_Days_night_movieposter.jpg'\n",
        "    if rank_title == '53_12_Angry_Men_(1957_film)':\n",
        "        url = 'https://upload.wikimedia.org/wikipedia/en/9/91/12_angry_men.jpg'\n",
        "    if rank_title == '72_Rosemary%27s_Baby_(film)':\n",
        "        url = 'https://upload.wikimedia.org/wikipedia/en/e/ef/Rosemarys_baby_poster.jpg'\n",
        "    if rank_title == '93_Harry_Potter_and_the_Deathly_Hallows_–_Part_2':\n",
        "        url = 'https://upload.wikimedia.org/wikipedia/en/d/df/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2.jpg'\n",
        "    title = rank_title[3:]\n",
        "    df_list.append({'ranking': int(title_list.index(title) + 1),\n",
        "                    'title': title,\n",
        "                    'poster_url': url})\n",
        "    r = requests.get(url)\n",
        "    # Download movie poster image\n",
        "    i = Image.open(BytesIO(r.content))\n",
        "    image_file_format = url.split('.')[-1]\n",
        "    i.save(folder_name + \"/\" + rank_title + '.' + image_file_format)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUCFF_-TWsvH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create DataFrame from list of dictionaries\n",
        "df = pd.DataFrame(df_list, columns = ['ranking', 'title', 'poster_url'])\n",
        "df = df.sort_values('ranking').reset_index(drop=True)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hcjUykC5WvLN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Relational databases and pandas\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('bestofrt_master.csv')\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOuoEOQ_WwMb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create SQLAlchemy Engine and empty bestofrt database\n",
        "# bestofrt.db will not show up in the Jupyter Notebook dashboard yet\n",
        "engine = create_engine('sqlite:///bestofrt.db')\n",
        "\n",
        "# Store cleaned master DataFrame ('df') in a table called master in bestofrt.db\n",
        "# bestofrt.db will be visible now in the Jupyter Notebook dashboard\n",
        "df.to_sql('master', engine, index=False)\n",
        "\n",
        "df_gather = pd.read_sql('SELECT * FROM master', engine)\n",
        "\n",
        "df_gather.head(3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z3_cAjPekECM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assess"
      ]
    },
    {
      "metadata": {
        "id": "AntSAP-HHu_S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Dirty Data - data with data quality issues or issues with content\n",
        "# Messy or Untidy Data - data with structural issues\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6qAIqP0lIIIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1QNq-cJkECU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clean"
      ]
    },
    {
      "metadata": {
        "id": "oFNEyJWukECW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define"
      ]
    },
    {
      "metadata": {
        "id": "8FeXybG9kECY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Code"
      ]
    },
    {
      "metadata": {
        "id": "J-ul38Y7kECa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['Animal'] = df['Animal'].str[2:]\n",
        "df['Body Weight (kg)'] = df['Body Weight (kg)'].str.replace('!', '.')\n",
        "df['Brain Weight (kg)'] = df['Brain Weight (kg)'].str.replace('!', '.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OKWuHPt0kECh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test"
      ]
    },
    {
      "metadata": {
        "id": "IkyKMQ_GkEDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
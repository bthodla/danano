{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "danano_data_wrangling.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ilguZU0QkECB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling Template"
      ]
    },
    {
      "metadata": {
        "id": "GCYq5Nb5kECE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gather"
      ]
    },
    {
      "metadata": {
        "id": "zQ_EZaLikECG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# Extract all the contents from a zipfile\n",
        "with zipfile.Zipfile('filename.zip', 'r') as myzip:\n",
        "  myzip.extractall()\n",
        "\n",
        "df = pd.read_csv('online-job-postings.csv')\n",
        "\n",
        "df.info\n",
        "df.head()\n",
        "\n",
        "df_clean = df.copy()\n",
        "\n",
        "df_clean = df_clean.rename(columns = {'old_col_name1':'new_col_name1',\n",
        "                                   'old_col_name2':'new_col_name2',\n",
        "                                   'old_col_name3':'new_col_name3'})\n",
        "\n",
        "replace_list = ['old_value1', 'old_value2', 'old_value3']\n",
        "\n",
        "for phrase in replace_list:\n",
        "  df_clean.StartDate.replace(phrase, 'new_value', inplace=True)\n",
        "  \n",
        "# Assertions in Python\n",
        "for phrase in replace_list:\n",
        "  assert phrase not in df_clean.StartDate.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zzw3UQYrm6aM",
        "colab_type": "code",
        "outputId": "7e7ce29e-5fea-43a8-a0d9-1258d897d046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "# Web Scraping\n",
        "import requests\n",
        "import os\n",
        "\n",
        "folder_name = 'ebert_reviews'\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "    \n",
        "url = 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save the HTML to a file\n",
        "for url in ebert_review_urls:\n",
        "    response = requests.get(url)\n",
        "    with open(os.path.join(folder_name, url.split('/')[-1]), mode = 'wb') as file:\n",
        "        file.write(response.content)\n",
        "              \n",
        "os.listdir(folder_name)\n",
        "\n",
        "import filecmp\n",
        "\n",
        "dc = filecmp.dircmp('ebert_reviews', 'ebert_reviews_solution')\n",
        "assert len(dc.common) == 88\n",
        "\n",
        "# Working with the HTML content in memory\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "with open (url) as file:\n",
        "    # soup = BeautifulSouop(url, 'lxml')\n",
        "    soup = BeautifulSoup(file, 'lxml')\n",
        "\n",
        "soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a17a07dc4683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# soup = BeautifulSouop(url, 'lxml')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "z3_cAjPekECM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assess"
      ]
    },
    {
      "metadata": {
        "id": "SwBLGVwtkECO",
        "colab_type": "code",
        "outputId": "5965deb4-ffaa-4d50-cd8f-9a9d5b68c25b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "folder = 'rt_html'\n",
        "for movie_html in os.listdir(folder):\n",
        "    with open(os.path.join(folder, movie_html)) as file:\n",
        "        # Your code here\n",
        "        # Note: a correct implementation may take ~15 seconds to run\n",
        "        soup = BeautifulSoup(file, 'lxml')\n",
        "        title = soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
        "        audience_score = soup.find('div', class_='audience-score meter').find('span').contents[0][:-1]\n",
        "        num_audience_ratings = soup.find('div', class_ = 'audience-info hidden-xs superPageFontColor')\n",
        "        num_audience_ratings = num_audience_ratings.find_all('div')[1].contents[2].strip().replace(',','')\n",
        "        \n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                        'audience_score': int(audience_score),\n",
        "                        'number_of_audience_ratings': int(num_audience_ratings)})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'audience_score', 'number_of_audience_ratings'])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<span class=\"mop-ratings-wrap__percentage\">\n",
            "                                        98%\n",
            "                                    </span>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r4ROLYWkPLcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_pickle('df_solution.pkl')\n",
        "df.sort_values('title', inplace = True)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "df_solution.sort_values('title', inplace = True)\n",
        "df_solution.reset_index(inplace = True, drop = True)\n",
        "pd.testing.assert_frame_equal(df, df_solution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YoRtljps141",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "for ebert_review in glob.glob('ebert_reviews/*.txt'):\n",
        "    with open(ebert_review, encoding='utf-8') as file:\n",
        "        title = file.readline()[:-1]\n",
        "        # Your code here\n",
        "        review_url = file.readline()[:-1]\n",
        "        review_text = file.read()\n",
        "\n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                       'review_url': review_url,\n",
        "                       'review_text': review_text})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'review_url', 'review_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0QAApEgwWar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_pickle('df_solution.pkl')\n",
        "df.sort_values('title', inplace = True)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "df_solution.sort_values('title', inplace = True)\n",
        "df_solution.reset_index(inplace = True, drop = True)\n",
        "pd.testing.assert_frame_equal(df, df_solution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUKg2b2a2gU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "a850b3f8-05cf-4cd9-861d-8a768c1cf27b"
      },
      "cell_type": "code",
      "source": [
        "!pip install wptools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wptools\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/5c/0d8af5532e44477edeb3dac81d3a611ea75827a18b6b4068c3cc2188bfe5/wptools-0.4.17-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from wptools) (2018.11.29)\n",
            "Collecting html2text (from wptools)\n",
            "  Downloading https://files.pythonhosted.org/packages/16/20/de2b458ef434713053dd83209a03a5431ebe0527c8e14d9ae7838ff67d8a/html2text-2018.1.9-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from wptools) (4.2.6)\n",
            "Collecting pycurl (from wptools)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/e4/0dbb8735407189f00b33d84122b9be52c790c7c3b25286826f4e1bdb7bde/pycurl-7.43.0.2.tar.gz (214kB)\n",
            "\u001b[K    100% |████████████████████████████████| 215kB 7.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycurl\n",
            "  Building wheel for pycurl (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/85/ae/ebf5ff0f1368869d082b4863df492bf54c661bf6306a2bdfde\n",
            "Successfully built pycurl\n",
            "Installing collected packages: html2text, pycurl, wptools\n",
            "Successfully installed html2text-2018.1.9 pycurl-7.43.0.2 wptools-0.4.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iS6H5a-t1O9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "1b4758ea-5492-4940-d9b0-4384fba5c1b4"
      },
      "cell_type": "code",
      "source": [
        "import wptools\n",
        "\n",
        "page = wptools.page('E.T._the_Extra-Terrestrial').get()\n",
        "page.data['image'][0]\n",
        "page.data['infobox']['director']\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en.wikipedia.org (query) E.T._the_Extra-Terrestrial\n",
            "en.wikipedia.org (parse) 73441\n",
            "www.wikidata.org (wikidata) Q11621\n",
            "www.wikidata.org (labels) P910|P18|P2508|Q30|Q229009|Q374540|Q676...\n",
            "www.wikidata.org (labels) P1874|P135|Q900414|P5008|P227|Q41417|Q1...\n",
            "www.wikidata.org (labels) P1804|P373|Q168383|P1040|Q1757366|P244|...\n",
            "www.wikidata.org (labels) P2130|P1265|P3110|P3141|P3933|Q130232|P...\n",
            "en.wikipedia.org (restbase) /page/summary/E.T._the_Extra-Terrestrial\n",
            "en.wikipedia.org (imageinfo) File:ET logo 3.svg|File:E t the extr...\n",
            "E.T. the Extra-Terrestrial (en) data\n",
            "{\n",
            "  WARNINGS: <dict(1)> extracts\n",
            "  aliases: <list(2)> E.T., ET\n",
            "  assessments: <dict(4)> United States, Film, Science Fiction, Lib...\n",
            "  claims: <dict(94)> P1562, P57, P272, P345, P31, P161, P373, P480...\n",
            "  description: <str(63)> 1982 American science fiction film direct...\n",
            "  exhtml: <str(570)> <p><i><b>E.T. the Extra-Terrestrial</b></i> i...\n",
            "  exrest: <str(549)> E.T. the Extra-Terrestrial is a 1982 American...\n",
            "  extext: <str(1731)> _**E.T. the Extra-Terrestrial**_ is a 1982 A...\n",
            "  extract: <str(1849)> <p class=\"mw-empty-elt\"></p><p><i><b>E.T. t...\n",
            "  image: <list(4)> {'kind': 'parse-image', 'file': 'File:E t the e...\n",
            "  infobox: <dict(18)> name, image, caption, director, producers, w...\n",
            "  iwlinks: <list(6)> https://commons.wikimedia.org/wiki/Category:E...\n",
            "  label: E.T. the Extra-Terrestrial\n",
            "  labels: <dict(174)> P910, P18, P2508, Q30, Q229009, Q374540, Q67...\n",
            "  length: 80,040\n",
            "  links: <list(463)> 12 Monkeys, 12 Years a Slave (film), 1941 (fi...\n",
            "  modified: <dict(2)> page, wikidata\n",
            "  pageid: 73441\n",
            "  parsetree: <str(99969)> <root><template><title>Redirect</title><...\n",
            "  random: Seema Malaka\n",
            "  redirects: <list(38)> {'pageid': 177061, 'ns': 0, 'title': 'E.T....\n",
            "  requests: <list(9)> query, parse, wikidata, labels, labels, labe...\n",
            "  title: E.T._the_Extra-Terrestrial\n",
            "  url: https://en.wikipedia.org/wiki/E.T._the_Extra-Terrestrial\n",
            "  url_raw: <str(67)> https://en.wikipedia.org/wiki/E.T._the_Extra-...\n",
            "  watchers: 290\n",
            "  what: film\n",
            "  wikibase: Q11621\n",
            "  wikidata: <dict(94)> AllMovie movie ID (P1562), director (P57), ...\n",
            "  wikidata_pageid: 13150\n",
            "  wikidata_url: https://www.wikidata.org/wiki/Q11621\n",
            "  wikitext: <str(79731)> {{Redirect|E.T.|other uses|ET (disambigua...\n",
            "}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[[Steven Spielberg]]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "IccRuT1M28fu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import wptools\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P9C9qR1p5sag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "title_list = [\n",
        " 'The_Wizard_of_Oz_(1939_film)',\n",
        " 'Citizen_Kane',\n",
        " 'The_Third_Man',\n",
        " 'Get_Out_(film)',\n",
        " 'Mad_Max:_Fury_Road',\n",
        " 'The_Cabinet_of_Dr._Caligari',\n",
        " 'All_About_Eve',\n",
        " 'Inside_Out_(2015_film)',\n",
        " 'The_Godfather',\n",
        " 'Metropolis_(1927_film)',\n",
        " 'E.T._the_Extra-Terrestrial',\n",
        " 'Modern_Times_(film)',\n",
        " 'It_Happened_One_Night',\n",
        " \"Singin'_in_the_Rain\",\n",
        " 'Boyhood_(film)',\n",
        " 'Casablanca_(film)',\n",
        " 'Moonlight_(2016_film)',\n",
        " 'Psycho_(1960_film)',\n",
        " 'Laura_(1944_film)',\n",
        " 'Nosferatu',\n",
        " 'Snow_White_and_the_Seven_Dwarfs_(1937_film)',\n",
        " \"A_Hard_Day%27s_Night_(film)\",\n",
        " 'La_Grande_Illusion',\n",
        " 'North_by_Northwest',\n",
        " 'The_Battle_of_Algiers',\n",
        " 'Dunkirk_(2017_film)',\n",
        " 'The_Maltese_Falcon_(1941_film)',\n",
        " 'Repulsion_(film)',\n",
        " '12_Years_a_Slave_(film)',\n",
        " 'Gravity_(2013_film)',\n",
        " 'Sunset_Boulevard_(film)',\n",
        " 'King_Kong_(1933_film)',\n",
        " 'Spotlight_(film)',\n",
        " 'The_Adventures_of_Robin_Hood',\n",
        " 'Rashomon',\n",
        " 'Rear_Window',\n",
        " 'Selma_(film)',\n",
        " 'Taxi_Driver',\n",
        " 'Toy_Story_3',\n",
        " 'Argo_(2012_film)',\n",
        " 'Toy_Story_2',\n",
        " 'The_Big_Sick',\n",
        " 'Bride_of_Frankenstein',\n",
        " 'Zootopia',\n",
        " 'M_(1931_film)',\n",
        " 'Wonder_Woman_(2017_film)',\n",
        " 'The_Philadelphia_Story_(film)',\n",
        " 'Alien_(film)',\n",
        " 'Bicycle_Thieves',\n",
        " 'Seven_Samurai',\n",
        " 'The_Treasure_of_the_Sierra_Madre_(film)',\n",
        " 'Up_(2009_film)',\n",
        " '12_Angry_Men_(1957_film)',\n",
        " 'The_400_Blows',\n",
        " 'Logan_(film)',\n",
        " 'All_Quiet_on_the_Western_Front_(1930_film)',\n",
        " 'Army_of_Shadows',\n",
        " 'Arrival_(film)',\n",
        " 'Baby_Driver',\n",
        " 'A_Streetcar_Named_Desire_(1951_film)',\n",
        " 'The_Night_of_the_Hunter_(film)',\n",
        " 'Star_Wars:_The_Force_Awakens',\n",
        " 'Manchester_by_the_Sea_(film)',\n",
        " 'Dr._Strangelove',\n",
        " 'Frankenstein_(1931_film)',\n",
        " 'Vertigo_(film)',\n",
        " 'The_Dark_Knight_(film)',\n",
        " 'Touch_of_Evil',\n",
        " 'The_Babadook',\n",
        " 'The_Conformist_(film)',\n",
        " 'Rebecca_(1940_film)',\n",
        " \"Rosemary%27s_Baby_(film)\",\n",
        " 'Finding_Nemo',\n",
        " 'Brooklyn_(film)',\n",
        " 'The_Wrestler_(2008_film)',\n",
        " 'The_39_Steps_(1935_film)',\n",
        " 'L.A._Confidential_(film)',\n",
        " 'Gone_with_the_Wind_(film)',\n",
        " 'The_Good,_the_Bad_and_the_Ugly',\n",
        " 'Skyfall',\n",
        " 'Rome,_Open_City',\n",
        " 'Tokyo_Story',\n",
        " 'Hell_or_High_Water_(film)',\n",
        " 'Pinocchio_(1940_film)',\n",
        " 'The_Jungle_Book_(2016_film)',\n",
        " 'La_La_Land_(film)',\n",
        " 'Star_Trek_(film)',\n",
        " 'High_Noon',\n",
        " 'Apocalypse_Now',\n",
        " 'On_the_Waterfront',\n",
        " 'The_Wages_of_Fear',\n",
        " 'The_Last_Picture_Show',\n",
        " 'Harry_Potter_and_the_Deathly_Hallows_–_Part_2',\n",
        " 'The_Grapes_of_Wrath_(film)',\n",
        " 'Roman_Holiday',\n",
        " 'Man_on_Wire',\n",
        " 'Jaws_(film)',\n",
        " 'Toy_Story',\n",
        " 'The_Godfather_Part_II',\n",
        " 'Battleship_Potemkin'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVvTuqjO5wSE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "folder_name = 'bestofrt_posters'\n",
        "# Make directory if it doesn't already exist\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsI86CDJ6aKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bf210e3-4a89-4953-822a-13dd35a46a00"
      },
      "cell_type": "code",
      "source": [
        "page = wptools.page('Skyfall', silent=True).get()\n",
        "page.data['image'][0]['url']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://upload.wikimedia.org/wikipedia/en/a/a7/Skyfall_poster.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "E5dHGgnt8XJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1839
        },
        "outputId": "4f6e4adc-1177-4147-dd9f-84bf6b839046"
      },
      "cell_type": "code",
      "source": [
        "# List of dictionaries to build and convert to a DataFrame later\n",
        "df_list = []\n",
        "image_errors = {}\n",
        "# images = {}\n",
        "for title in title_list:\n",
        "    try:\n",
        "        # This cell is slow so print ranking to gauge time remaining\n",
        "        ranking = title_list.index(title) + 1\n",
        "        print(ranking)\n",
        "        page = wptools.page(title, silent=True).get()\n",
        "        # Your code here (three lines)\n",
        "        images = page.data['image']\n",
        "        # First image is usually the poster\n",
        "        first_image_url = images[0]['url']\n",
        "        r = requests.get(first_image_url)\n",
        "        # Download movie poster image\n",
        "        i = Image.open(BytesIO(r.content))\n",
        "        image_file_format = first_image_url.split('.')[-1]\n",
        "        i.save(folder_name + \"/\" + str(ranking) + \"_\" + title + '.' + image_file_format)\n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'ranking': int(ranking),\n",
        "                        'title': title,\n",
        "                        'poster_url': first_image_url})\n",
        "    \n",
        "    # Not best practice to catch all exceptions but fine for this short script\n",
        "    except Exception as e:\n",
        "        print(str(ranking) + \"_\" + title + \": \" + str(e))\n",
        "        image_errors[str(ranking) + \"_\" + title] = images"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "API error: {'code': 'invalidtitle', 'info': 'Bad title \"A_Hard_Day%27s_Night_(film)\".', 'docref': 'See https://en.wikipedia.org/w/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &lt;https://lists.wikimedia.org/mailman/listinfo/mediawiki-api-announce&gt; for notice of API deprecations and breaking changes.'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "22_A_Hard_Day%27s_Night_(film): https://en.wikipedia.org/w/api.php?action=parse&formatversion=2&contentmodel=text&disableeditsection=&disablelimitreport=&disabletoc=&prop=text|iwlinks|parsetree|wikitext|displaytitle|properties&redirects&page=A_Hard_Day%2527s_Night_%28film%29\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "64_Dr._Strangelove: cannot identify image file <_io.BytesIO object at 0x7fc5e6711678>\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "API error: {'code': 'invalidtitle', 'info': 'Bad title \"Rosemary%27s_Baby_(film)\".', 'docref': 'See https://en.wikipedia.org/w/api.php for API usage. Subscribe to the mediawiki-api-announce mailing list at &lt;https://lists.wikimedia.org/mailman/listinfo/mediawiki-api-announce&gt; for notice of API deprecations and breaking changes.'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "72_Rosemary%27s_Baby_(film): https://en.wikipedia.org/w/api.php?action=parse&formatversion=2&contentmodel=text&disableeditsection=&disablelimitreport=&disabletoc=&prop=text|iwlinks|parsetree|wikitext|displaytitle|properties&redirects&page=Rosemary%2527s_Baby_%28film%29\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "83_Hell_or_High_Water_(film): 'image'\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N1QNq-cJkECU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clean"
      ]
    },
    {
      "metadata": {
        "id": "oFNEyJWukECW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define"
      ]
    },
    {
      "metadata": {
        "id": "8FeXybG9kECY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Code"
      ]
    },
    {
      "metadata": {
        "id": "J-ul38Y7kECa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OKWuHPt0kECh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test"
      ]
    },
    {
      "metadata": {
        "id": "IkyKMQ_GkEDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
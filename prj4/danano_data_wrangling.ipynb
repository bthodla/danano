{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "danano_data_wrangling.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ilguZU0QkECB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Wrangling Template"
      ]
    },
    {
      "metadata": {
        "id": "GCYq5Nb5kECE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gather"
      ]
    },
    {
      "metadata": {
        "id": "zQ_EZaLikECG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# Extract all the contents from a zipfile\n",
        "with zipfile.Zipfile('filename.zip', 'r') as myzip:\n",
        "  myzip.extractall()\n",
        "\n",
        "df = pd.read_csv('online-job-postings.csv')\n",
        "\n",
        "df.info\n",
        "df.head()\n",
        "\n",
        "df_clean = df.copy()\n",
        "\n",
        "df_clean = df_clean.rename(columns = {'old_col_name1':'new_col_name1',\n",
        "                                   'old_col_name2':'new_col_name2',\n",
        "                                   'old_col_name3':'new_col_name3'})\n",
        "\n",
        "replace_list = ['old_value1', 'old_value2', 'old_value3']\n",
        "\n",
        "for phrase in replace_list:\n",
        "  df_clean.StartDate.replace(phrase, 'new_value', inplace=True)\n",
        "  \n",
        "# Assertions in Python\n",
        "for phrase in replace_list:\n",
        "  assert phrase not in df_clean.StartDate.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zzw3UQYrm6aM",
        "colab_type": "code",
        "outputId": "7e7ce29e-5fea-43a8-a0d9-1258d897d046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "# Web Scraping\n",
        "import requests\n",
        "import os\n",
        "\n",
        "folder_name = 'ebert_reviews'\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "    \n",
        "url = 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save the HTML to a file\n",
        "for url in ebert_review_urls:\n",
        "    response = requests.get(url)\n",
        "    with open(os.path.join(folder_name, url.split('/')[-1]), mode = 'wb') as file:\n",
        "        file.write(response.content)\n",
        "              \n",
        "os.listdir(folder_name)\n",
        "\n",
        "import filecmp\n",
        "\n",
        "dc = filecmp.dircmp('ebert_reviews', 'ebert_reviews_solution')\n",
        "assert len(dc.common) == 88\n",
        "\n",
        "# Working with the HTML content in memory\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "with open (url) as file:\n",
        "    # soup = BeautifulSouop(url, 'lxml')\n",
        "    soup = BeautifulSoup(file, 'lxml')\n",
        "\n",
        "soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a17a07dc4683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# soup = BeautifulSouop(url, 'lxml')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.rottentomatoes.com/m/et_the_extraterrestrial'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "z3_cAjPekECM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assess"
      ]
    },
    {
      "metadata": {
        "id": "SwBLGVwtkECO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5965deb4-ffaa-4d50-cd8f-9a9d5b68c25b"
      },
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "folder = 'rt_html'\n",
        "for movie_html in os.listdir(folder):\n",
        "    with open(os.path.join(folder, movie_html)) as file:\n",
        "        # Your code here\n",
        "        # Note: a correct implementation may take ~15 seconds to run\n",
        "        soup = BeautifulSoup(file, 'lxml')\n",
        "        title = soup.find('title').contents[0][:-len(' - Rotten Tomatoes')]\n",
        "        audience_score = soup.find('div', class_='audience-score meter').find('span').contents[0][:-1]\n",
        "        num_audience_ratings = soup.find('div', class_ = 'audience-info hidden-xs superPageFontColor')\n",
        "        num_audience_ratings = num_audience_ratings.find_all('div')[1].contents[2].strip().replace(',','')\n",
        "        \n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                        'audience_score': int(audience_score),\n",
        "                        'number_of_audience_ratings': int(num_audience_ratings)})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'audience_score', 'number_of_audience_ratings'])\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<span class=\"mop-ratings-wrap__percentage\">\n",
            "                                        98%\n",
            "                                    </span>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r4ROLYWkPLcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_pickle('df_solution.pkl')\n",
        "df.sort_values('title', inplace = True)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "df_solution.sort_values('title', inplace = True)\n",
        "df_solution.reset_index(inplace = True, drop = True)\n",
        "pd.testing.assert_frame_equal(df, df_solution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YoRtljps141",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# List of dictionaries to build file by file and later convert to a DataFrame\n",
        "df_list = []\n",
        "for ebert_review in glob.glob('ebert_reviews/*.txt'):\n",
        "    with open(ebert_review, encoding='utf-8') as file:\n",
        "        title = file.readline()[:-1]\n",
        "        # Your code here\n",
        "        review_url = file.readline()[:-1]\n",
        "        review_text = file.read()\n",
        "\n",
        "        # Append to list of dictionaries\n",
        "        df_list.append({'title': title,\n",
        "                       'review_url': review_url,\n",
        "                       'review_text': review_text})\n",
        "df = pd.DataFrame(df_list, columns = ['title', 'review_url', 'review_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0QAApEgwWar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_solution = pd.read_pickle('df_solution.pkl')\n",
        "df.sort_values('title', inplace = True)\n",
        "df.reset_index(inplace = True, drop = True)\n",
        "df_solution.sort_values('title', inplace = True)\n",
        "df_solution.reset_index(inplace = True, drop = True)\n",
        "pd.testing.assert_frame_equal(df, df_solution)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iS6H5a-t1O9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import wptools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "drsw8gjy1R2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "page = wptools.page('E.T._the_Extra-Terrestrial').get()\n",
        "page.data['image'][0]\n",
        "page.data['infobox']['director']\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1QNq-cJkECU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clean"
      ]
    },
    {
      "metadata": {
        "id": "oFNEyJWukECW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define"
      ]
    },
    {
      "metadata": {
        "id": "8FeXybG9kECY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Code"
      ]
    },
    {
      "metadata": {
        "id": "J-ul38Y7kECa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OKWuHPt0kECh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Test"
      ]
    },
    {
      "metadata": {
        "id": "IkyKMQ_GkEDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
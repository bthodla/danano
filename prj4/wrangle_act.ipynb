{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wrangle_act.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bthodla/danano/blob/master/prj4/wrangle_act.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6MHgHyKUt_Uj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gathering data\n",
        "\n",
        "1.   Load the \"twitter-archive-enhanced.csv\" into a dataframe\n",
        "2.   Load the \"image_predictions.tsv\" (the Tweet image predictions) hosted on Udacity servers programmatically using the \"requests\" library (URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv)\n",
        "3. Using tweet ids from (1) above and the Twitter API, load information such as \"retweet count\" and \"favorite count\" and any other interesting data items and store the entire set of data relating to a tweet in a JSON file called \"tweet_json.txt\"; then read this file line by line into a data frame and include tweet id, retweet count, favorite count and any other data items of interest\n",
        "4. Consumer API keys: \n",
        "    \n",
        "    Z22dLMPEOtCL2ayqnPTbFg3sK (API key)\n",
        "    \n",
        "    SuaxZay016BTIpzrYszo9Dbo0jQd38FZ8SUi0bDyy8hU6jMKdj (API secret key)\n",
        "    \n",
        "    Access token & access token secret\n",
        "\n",
        "    14299634-DHvEoZI9bR2D5WOZWf82MjHX6vEnPRIosIrli6ueb (Access token)\n",
        "\n",
        "    nvba5wXGFrEcYKmQjztu40wsr0vG2pXnQShE2ZQv6I313 (Access token secret)\n",
        "\n",
        "    Read and write (Access level)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CLeZDiDMhHv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import io\n",
        "import tweepy\n",
        "import json\n",
        "from google.colab import drive\n",
        "import yaml\n",
        "import time\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0M0qep9Flhtx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_yaml_file(filename: str) -> dict:\n",
        "    twitter_keys = {}\n",
        "\n",
        "    with open(filename, 'r') as ymlfile:\n",
        "        cfg = yaml.safe_load(ymlfile)\n",
        "    \n",
        "    twitter_keys['consumer_key'] = cfg['twitter']['consumer']['key']\n",
        "    twitter_keys['consumer_secret'] = cfg['twitter']['consumer']['secret']\n",
        "    twitter_keys['access_token'] = cfg['twitter']['access']['token']\n",
        "    twitter_keys['access_token_secret'] = cfg['twitter']['access']['token-secret']\n",
        "\n",
        "    return twitter_keys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbUVJeB4p56h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_file(file_name, lines = 10):\n",
        "    with open(file_name, 'r') as f:\n",
        "        for _ in range(lines):\n",
        "            print (f.readline())\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OAAc2CBNljDo",
        "colab_type": "code",
        "outputId": "f025a5ac-673e-486e-8def-b4cc85ef6f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "twitter_keys_yaml_file = '/content/gdrive/My Drive/Colab Notebooks/twitter_keys.yaml'\n",
        "tweet_json_file = '/content/gdrive/My Drive/Colab Notebooks/tweet_json.txt'\n",
        "\n",
        "\"\"\"\n",
        "with open(twitter_keys_yaml_file, encoding='utf-8') as file:\n",
        "    line = file.readline()\n",
        "    while line:\n",
        "        line = file.readline()\n",
        "        print(line)\n",
        "\"\"\"\n",
        "print(load_yaml_file(twitter_keys_yaml_file))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "{'consumer_key': 'Z22dLMPEOtCL2ayqnPTbFg3sK', 'consumer_secret': 'SuaxZay016BTIpzrYszo9Dbo0jQd38FZ8SUi0bDyy8hU6jMKdj', 'access_token': '14299634-DHvEoZI9bR2D5WOZWf82MjHX6vEnPRIosIrli6ueb', 'access_token_secret': 'nvba5wXGFrEcYKmQjztu40wsr0vG2pXnQShE2ZQv6I313'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6C3qa35miEux",
        "colab_type": "code",
        "outputId": "f69cf1c6-ce41-495f-e826-280998e445de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 1. Load the file \"twitter-archive-enhanced.csv\" into a dataframe\n",
        "twitter_archive_file_url = 'https://raw.githubusercontent.com/bthodla/danano/master/prj4/twitter-archive-enhanced.csv'\n",
        "\n",
        "tweets_df = pd.read_csv(twitter_archive_file_url)\n",
        "\n",
        "tweet_count = tweets_df.shape[0]\n",
        "print ('%s %d' % ('Tweet Count: ', tweet_count))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweet Count:  2356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YXfHmi0ene-L",
        "colab_type": "code",
        "outputId": "4cda8040-027b-4374-e004-2972d496c0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# 2. Load the \"image_predictions.tsv\" (the Tweet image predictions) hosted on Udacity servers programmatically using the \"requests\" library\n",
        "\n",
        "image_predictions_file_url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
        "\n",
        "url_data = requests.get(image_predictions_file_url).content\n",
        "\n",
        "img_pred_df = pd.read_csv(io.StringIO(url_data.decode('utf-8')), sep = '\\t')\n",
        "\n",
        "img_pred_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2075, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "uXGoehx6nemP",
        "colab_type": "code",
        "outputId": "c2d634fd-d3c4-4a79-dedd-e5593057fa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\" 3. Using tweet ids from tweet_df and the Twitter API, load information such as \"retweet count\" and \"favorite count\" and any other interesting data items \n",
        "and store the entire set of data relating to a tweet in a JSON file called \"tweet_json.txt\"; then read this file line by line into a data frame and include \n",
        "tweet id, retweet count, favorite count and any other data items of interest\n",
        "\"\"\"\n",
        "\n",
        "twitter_keys = load_yaml_file(twitter_keys_yaml_file)\n",
        "consumer_key = twitter_keys['consumer_key']\n",
        "consumer_secret = twitter_keys['consumer_secret']\n",
        "access_token = twitter_keys['access_token']\n",
        "access_token_secret = twitter_keys['access_token_secret']\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
        "\n",
        "error_tweets = {}\n",
        "tweet_offset = 0\n",
        "tweet_batch = 100\n",
        "tweets_remaining = 0\n",
        "\n",
        "# Delete the file first so that each run can add content fresh\n",
        "if os.path.isfile(tweet_json_file):\n",
        "    os.remove(tweet_json_file)\n",
        "\n",
        "with open(tweet_json_file, mode = 'a', encoding = 'utf-8') as f:\n",
        "    while tweet_batch:\n",
        "        tweet_ids = tweets_df[tweet_offset:tweet_offset + tweet_batch]['tweet_id']\n",
        "        for tweet_id in tweet_ids:\n",
        "            try:\n",
        "                status = api.get_status(tweet_id)\n",
        "                f.write(json.dumps(status._json) + '\\n')\n",
        "\n",
        "            except tweepy.TweepError as e:\n",
        "                error_tweets[status.id] = e\n",
        "            \n",
        "        tweets_remaining = tweet_count - tweet_offset\n",
        "        tweet_batch = tweet_batch if tweet_batch < tweets_remaining else tweets_remaining\n",
        "        tweet_offset += tweet_batch\n",
        "        # print ('%s %d %s %d' % ('Tweets Remaining: ', tweets_remaining, 'Tweet Offset: ', tweet_offset))\n",
        "        # time.sleep(1 * 5)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rate limit reached. Sleeping for: 771\n",
            "Rate limit reached. Sleeping for: 772\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tafWMMk53G23",
        "colab_type": "code",
        "outputId": "a4e4f70e-4fb5-4343-c523-81a695191da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with open(tweet_json_file, mode = 'r', encoding = 'utf-8') as f:\n",
        "    print(len(f.readlines()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dAgIUK19TShf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read \"tweet_json.txt\" file line by line into a data frame and include tweet id, retweet count, favorite count and any other data items of interest\n",
        "\n",
        "columns = ['tweet_id', 'text', 'retweet_count', 'favorite_count', 'retweeted', 'favorited', 'media_url']\n",
        "tweets_mini_df = pd.DataFrame(columns = columns)\n",
        "\n",
        "index = 0\n",
        "with open(tweet_json_file, mode = 'r', encoding = 'utf-8') as f:\n",
        "    for tweet in f:\n",
        "        tweet_json = json.loads(tweet)\n",
        "        tweet_id = tweet_json['id']\n",
        "        text = tweet_json['text']\n",
        "        retweet_count = tweet_json['retweet_count']\n",
        "        favorite_count = tweet_json['favorite_count']\n",
        "        retweeted = tweet_json['retweeted']\n",
        "        favorited = tweet_json['favorited']\n",
        "        try:\n",
        "            media_url = tweet_json['entities']['media'][0]['media_url_https']\n",
        "        except KeyError as e:\n",
        "            media_url = ''\n",
        "\n",
        "        tweets_mini_df.loc[index] = pd.Series({'tweet_id': tweet_id, \n",
        "                                        'text': text, \n",
        "                                        'retweet_count': retweet_count, \n",
        "                                        'favorite_count': favorite_count,\n",
        "                                        'retweeted': retweeted,\n",
        "                                        'favorited': favorited,\n",
        "                                        'media_url': media_url})\n",
        "        index +=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MvXhOVR8FZOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9fa51098-9e2e-4bff-d107-6ab278566f42"
      },
      "cell_type": "code",
      "source": [
        "tweets_mini_df.head()\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweeted</th>\n",
              "      <th>favorited</th>\n",
              "      <th>media_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892420643555336193</td>\n",
              "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
              "      <td>8226</td>\n",
              "      <td>37748</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>892177421306343426</td>\n",
              "      <td>This is Tilly. She's just checking pup on you....</td>\n",
              "      <td>6079</td>\n",
              "      <td>32430</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>891815181378084864</td>\n",
              "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
              "      <td>4023</td>\n",
              "      <td>24427</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>891689557279858688</td>\n",
              "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
              "      <td>8379</td>\n",
              "      <td>41085</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/media/DF_q7IAWsAEuuN8.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>891327558926688256</td>\n",
              "      <td>This is Franklin. He would like you to stop ca...</td>\n",
              "      <td>9082</td>\n",
              "      <td>39281</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id                                               text  \\\n",
              "0  892420643555336193  This is Phineas. He's a mystical boy. Only eve...   \n",
              "1  892177421306343426  This is Tilly. She's just checking pup on you....   \n",
              "2  891815181378084864  This is Archie. He is a rare Norwegian Pouncin...   \n",
              "3  891689557279858688  This is Darla. She commenced a snooze mid meal...   \n",
              "4  891327558926688256  This is Franklin. He would like you to stop ca...   \n",
              "\n",
              "  retweet_count favorite_count retweeted favorited  \\\n",
              "0          8226          37748     False     False   \n",
              "1          6079          32430     False     False   \n",
              "2          4023          24427     False     False   \n",
              "3          8379          41085     False     False   \n",
              "4          9082          39281     False     False   \n",
              "\n",
              "                                         media_url  \n",
              "0  https://pbs.twimg.com/media/DGKD1-bXoAAIAUK.jpg  \n",
              "1                                                   \n",
              "2                                                   \n",
              "3  https://pbs.twimg.com/media/DF_q7IAWsAEuuN8.jpg  \n",
              "4                                                   "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "tj0ikwBvF_qT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assessing data\n",
        "\n",
        "Key Points\n",
        "\n",
        "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
        "\n",
        "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
        "\n",
        "* Cleaning includes merging individual pieces of data according to the rules of tidy data.\n",
        "\n",
        "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This unique rating system is a big part of the popularity of WeRateDogs.\n",
        "\n",
        "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n"
      ]
    }
  ]
}